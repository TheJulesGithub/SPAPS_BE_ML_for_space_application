{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scientist workflow\n",
    "\n",
    "Let's begin a full data scientist workflow on a simplified use case. \n",
    "\n",
    "**Situation**: Today Thermal Models (also called TMM: Thermal Mathematical Models) are very (very) slow - order of magnitude: 1 hours per simulation. For a complete thermal analysis, thousand of simulations have to be launch, to test the various space environment (test the different manoevers, on various date of the year, with various equipement ON/OFF...). \n",
    "\n",
    "Your purpose is to propose a Machine learning model permitting to *emulate* the TMM with a drastically reduced computing time.\n",
    "\n",
    "**Chalenge**:\n",
    "1. Find a Machine learning model which *emulate* the best TMM behaviour. More precisely, you have to propose an ML model with error < 1°.\n",
    "2. Your model shall be run a simulation on a reasonable computing time: < 1 second for one orbit simulated.\n",
    "\n",
    "**TMM used**: You will use a simplified model. This model is composed by a satellite with 45 thermal nodes (45 temperatures are outputed by the model). \n",
    "\n",
    "![img/train_sat.png](img/train_sat.png)\n",
    "*Illustration: the satellite used. Left: external model, right internal model.*\n",
    "\n",
    "* 9 TMM Input: \n",
    "\n",
    "    * 6 dissipation parameters: in [0.1, 2]\n",
    "        * QI_BATTERY: dissipation of the battery \n",
    "        * QI EPC: dissipation of the EPC: Electronic Power Converter\n",
    "        * QI_OMUX: dissipation of the OMUX: Output Multiplexer\n",
    "        * QI_PCDU: dissipation of the PCDU (Power Conditioning and Distribution Unit)\n",
    "        * QI_TRANSPONDER: dissipation of the transponder\n",
    "        * QI_TWT: Dissipation of the Travelling Wave Tube (repeater)\n",
    "    * 3 coupling parameters: in [0.1 ; 5]\n",
    "        * Wall_MLI: Coefiscient of heat insulation of the MLI (Multi Layer Insulation)\n",
    "        * Wall_Units: Coeffiscient of heat transfert between the equipements and the wall  \n",
    "        * Wall_Wall: : Coeffiscient of rejection of heat between the wall and space (measure efficiency of the heat pipes).\n",
    "\n",
    "\n",
    "* TMM Output: 45 Temepratures (one per node).\n",
    "\n",
    "**Work**:\n",
    "1. Generate data\n",
    "2. Pre-process data (train test split, ...)\n",
    "3. Choose a reference model and a loss function\n",
    "4. Choose and train your ML model\n",
    "5. Evaluate models (scores, comparison to reference, robustness, ...)\n",
    "6. [facultative] Optimize the hyper-parameters of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import usefull libs here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "# Usefull\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Linear model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Gaussian process\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF, Matern, RationalQuadratic, ExpSineSquared, ConstantKernel\n",
    "\n",
    "# Other usefull models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Hyper-parameters tunning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0/ Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General confs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_input = \"data/input_df.pickle\"\n",
    "filename_outputs = \"data/target_df.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read filename containing the inputs...\n",
    "with open(filename_input, 'rb') as f:\n",
    "    df_in = pickle.load(f)\n",
    "    \n",
    "# ... and the outputs\n",
    "with open(filename_outputs, 'rb') as f:\n",
    "    df_out = pickle.load(f)\n",
    "\n",
    "    \n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-process data: Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last column (contains the node \"space\", always at -269°C)\n",
    "df_out = df_out.drop(columns=44)\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-process data: Transform into Numpy DataFrame**\n",
    "\n",
    "More convenient for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_in, np_out = df_in.values, df_out.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Exercice 1: Pre-process data\n",
    "\n",
    "**Purpose of the exercice:**: Find in autonomy the better way to pre-process data.\n",
    "\n",
    "**Instructions**:\n",
    "1. Split data into *train* and *test* sample. You can use the sklearn `train_test_split` to do that. (just search on Google)\n",
    "2. *Scale* your data using the sklearn `StandardScaler` (just google it)\n",
    "3. Analyse the data: plot values of T° for node 14 before and after scaling.\n",
    "\n",
    "*Important note about scaling*: \n",
    "A scaler works in two steps: \n",
    "1. `fit`: compute statistics on the distribution (e.g. the average and std values of the dataset for `StandardScaler`)\n",
    "2. `transform`: effectively apply the operation of scaling (e.g. substract by average value and divide by std).\n",
    "\n",
    "The operation 1. (`fit`) must be performed on **Train** data only to get sure no information of the **validation** sample is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Train test split to avoid overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: `train_test_split` also shuffle data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Scaling\n",
    "\n",
    "We choose to scale the data. It is a process often used to \"help\" the models prediction (better scores when trained on scaled data). \n",
    "\n",
    "In this BE, we choose to use `StandardScaler`. See [this post](https://stackoverflow.com/questions/40758562/can-anyone-explain-me-standardscaler) for explanations.\n",
    "\n",
    "Note that the scaler is fitted on **train** data only. We are sure that no information is transmitted between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the unscaling operation, just apply `scaler_out.inverse_transform(y_data_to_unscale)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Analyze your data\n",
    "\n",
    "Let's visualize the scaling effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scaling effect on node:\n",
    "node_id = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, scaled data ranges between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usefull function**\n",
    "\n",
    "Here is a usefull function to analyse your data. It permits to show the distribution of values for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "plt.boxplot(y_train)\n",
    "plt.title(\"Ditribution of T°\")\n",
    "plt.xlabel(\"Node id\")\n",
    "plt.ylabel(\"T°\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/ Choose the cost function\n",
    "\n",
    "Choose the criterion of evaluation of your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of criterions:\n",
    "\n",
    "\n",
    "def compute_quality_criterions(y_pred, y_ref):\n",
    "    \"\"\"\n",
    "    Compute all the criterion of quality of your prediction. \n",
    "    Permits to efficiently compare models quality regarding multiple criterions.\n",
    "    \n",
    "    :return: dict containing:\n",
    "        * Key: name of the criterion\n",
    "        * Value: Value of the criterion\n",
    "    \"\"\"\n",
    "    return {\"mae\": mean_absolute_error(y_pred, y_ref), # mean absolute error\n",
    "            \"mse\": mean_squared_error(y_pred, y_ref),  # mean squared error\n",
    "            \"std\": np.std(y_pred - y_ref).mean(),  # standard deviation \n",
    "            \"max_absolute_error\": np.max(np.max(np.abs(y_pred - y_ref))),  # maximal absolute error \n",
    "           }\n",
    "\n",
    "def print_quality_criterion(y_pred, y_ref):\n",
    "    \"\"\"\n",
    "    Display the quality criterions.\n",
    "    \"\"\"    \n",
    "    d = compute_quality_criterions(y_pred, y_ref)\n",
    "       \n",
    "    for k, v in d.items():\n",
    "        # ex: mae: 0.1\n",
    "        print(f\"{k}: {v:.1f}\")  # .1f: 1 digit after coma       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to unscale your data BEFORE applying the criterion (else, no sense)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3/ Reference model\n",
    "\n",
    "Choose a naive model permitting to have a reference.\n",
    "\n",
    "In this section, I show you an example of code to reproduce. The only element to modify is the model choosen (line `model = ...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to use\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate quality of the *reference* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation sample\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Un-scale the prediction (remember, X and y are scaled !)\n",
    "y_pred = scaler_out.inverse_transform(y_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the scores on this model\n",
    "print_quality_criterion(y_pred, y_test)\n",
    "\n",
    "# Plot the dispertion of errors for each node.\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.title(\"Difference prediction - reference on TEST sample\")\n",
    "plt.xlabel(\"Node id\")\n",
    "plt.ylabel(\"T°\")\n",
    "plt.boxplot(y_pred - y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bilan**: Ok, the linear regression model is very bad. \n",
    "\n",
    "But we have our reference. Let's try now to do a better job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/ Exercice 2: Benchmark ML models\n",
    "\n",
    "\n",
    "**Purpose of the exercice:** This is the main exercice. Purpose is to test multiple machine learning models and compare them. Through this exercice, I want to show you a realistic example of how a data science work requires engineering.\n",
    "\n",
    "**Instructions:**\n",
    "1. Code your own function containing the full workflow (train, predict, `print_quality_criterion`, display boxplots)\n",
    "\n",
    "Test this function on various ML models, I have choosen various models from the litterature. **Of course, this work have to be performed by the Data scientist** (not enought time in this BE).\n",
    "\n",
    "2. xgboost (see `XGBRegressor` on Google)\n",
    "3. Gaussian Process (see `GaussianProcessRegressor` on Google)\n",
    "4. *[More difficult]* Polynomial regression (Use the sklearn `PolynomialFeatures`). If it's too difficult, see answer in [this stack overflow post](https://stackoverflow.com/questions/54891965/multivariate-polynomial-regression-with-python).\n",
    "5. *[Facultative]*: Test other ML approaches. You can find [here](https://scikit-learn.org/stable/supervised_learning.html) the regression models available on sklearn\n",
    "6. *[Facultative]*: Test Multi-Layer Perceptron\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Build your workflow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 XGBOOST\n",
    "\n",
    "XGBoost is a technique of ML using trees. Read [this doc](https://medium.com/analytics-vidhya/introduction-to-xgboost-algorithm-d2e7fad76b04) for a gentle introduction, and [this one](https://xgboost.readthedocs.io/en/stable/tutorials/model.html) for a details. \n",
    "\n",
    "![img/xgboost.png](img/xgboost.png)\n",
    "\n",
    "*Illusration of the XGBoost prediction:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost without scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost with scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3/ Gaussian process\n",
    "\n",
    "Find a very good introduction to Gaussian Process here: https://distill.pub/2019/visual-exploration-gaussian-processes/.\n",
    "\n",
    "In a nutshell, GPs (Gaussian Processes) are a mixture of gaussian estimator. \n",
    "\n",
    "![img/gaussian_process.png](img/gaussian_process.png)\n",
    "\n",
    "*Illustration of a Gaussian process regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Process without scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Process with scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4/ Polynomial regression\n",
    "\n",
    "If you are blocked, see [this stackoverflow post](https://stackoverflow.com/questions/54891965/multivariate-polynomial-regression-with-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5/ Other models\n",
    "\n",
    "\n",
    "Test other ML approaches. You can find [here](https://scikit-learn.org/stable/supervised_learning.html) the regression models available on sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultiOutputRegressor**\n",
    "\n",
    "You may want to test models specialized in each feature (here, build 44 models, one per node). This (naive) approach is usefull to test sklearn models managing single outputs.\n",
    "\n",
    "Detailes [here](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6/ Multi-Layer Perceptron\n",
    "\n",
    "This is an introduction to MLP. If you are begining with Neural Network, we advise to use the [Keras](https://www.tensorflow.org/tutorials/keras/regression?hl=fr#regression_with_a_deep_neural_network_dnn) framework.\n",
    "\n",
    "Keras is part of the Tensorflow project (Google): one of the main Neural Network library for Python. The other main Neural Network library is [pytorch](https://pytorch.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# 1/ Define your network\n",
    "# ---------------------------\n",
    "\n",
    "# Initiate the network in \"sequential\" mode\n",
    "model = Sequential() \n",
    "\n",
    "# Layer 1\n",
    "model.add(Dense(30, input_shape=(X_train.shape[1],)))  # input shape must be specified in layer 1\n",
    "# X_train.shape[1] = 12 -> 12 parameters in input of the network\n",
    "\n",
    "# Layer 2, 3, ... (one line per layer)\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(30))\n",
    "\n",
    "# Last layer shall predict 45 Temperatures (`y_train.shape[1]`: nb of columns of the outputs (T°))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "# 2/ Compile model\n",
    "# ---------------------------\n",
    "# This command \"compile\" the model, creating the C++ graph of computation.\n",
    "# Also permits to choose some hyper-parameters\n",
    "model.compile(loss='mean_squared_error',  # Choose the cost function (here MSE)\n",
    "              optimizer='adam',  # choose the optimization algorithm used (here ADAM: state of the art)\n",
    "              )\n",
    "\n",
    "# 3/ Display layering of your network\n",
    "# ---------------------------\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4/ Train model\n",
    "# ---------------------------\n",
    "model.fit(X_train_scaled,\n",
    "          y_train_scaled,\n",
    "          epochs=60,  # Number of iteration of the training algorithm\n",
    "          validation_data=(X_test_scaled, y_test_scaled),\n",
    "          verbose=1  # verbosity of the logs: 0 for no message\n",
    "         )\n",
    "\n",
    "# 5/ Validate\n",
    "# ---------------------------\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_out.inverse_transform(y_pred_scaled)\n",
    "\n",
    "evaluate_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5/ Execrice 3: Optimize your model\n",
    "\n",
    "You have found some interesting models. But you have tested it in default configuration... Each models have several parameters (e.g. `n_estimators, max_depth, min_child_weight...` for XGBOOST). You can modify these parameters to see if it's increase (or decrease) the performance. This process is called **hyper-parameters tunning**. It is a mandatory step in the data scientist workflow.\n",
    "\n",
    "**Purpose of the exercice:** Test tools to search the better set of hyper-parameters.\n",
    "\n",
    "**Instructions:**\n",
    "1. From an example of code, optimize manually the XGBOOST model proposed. \n",
    "2. Evaluate in a loop Polynom model from degree 2 to degree 5\n",
    "3. Use the `RandomSearchCV` algorithm to automate the process\n",
    "4. Use a state of the art algorithm (from `hyperopt` library) to select the better set of hyper-parameters\n",
    "\n",
    "Find the best model !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1/ Tune manually an XGBoost model\n",
    "\n",
    "Here are all the hyper-parameters of the XGBoost. Try to find manually the best set of hyper-parameters. Find [here](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor) the list of available hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(max_depth= 6,  # maximum depth of the trees estimators\n",
    "                    gamma=0.1,  # min loss reduction required to create a new leaf\n",
    "                    learning_rate=0.004,  # Learning rate of the optim. algorithm\n",
    "                    n_estimators=200,  # Number of trees\n",
    "                    subsample=0.7,  # % of the training \n",
    "                    colsample_bytree=0.7,  # % of cols used to construct each tree\n",
    "                    verbosity=1  # do not touch this (level of logs)\n",
    "                   )\n",
    "\n",
    "# Test with and without scaling\n",
    "train_evaluate(model=xgbr, scaled=True)\n",
    "\n",
    "train_evaluate(model=xgbr, scaled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2/ Test multiple polynom degree\n",
    "\n",
    "On step toward automation: test all polynom from degree 2 to degree 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3/ Automating Hyper-parameter search\n",
    "\n",
    "**Basic approach**\n",
    "\n",
    "You can automate the hyper-parameter tunning based on a very simple tool: `RandomSearchCV`. It consist in:\n",
    "\n",
    "* A. Detail the list of parameters to tune (and their ranges of values)\n",
    "* B. The algorithm will choose randomly set of hyper-parameters and evaluate the corresponding trained model\n",
    "    * This action is done multiple times (`n_iter`)\n",
    "    * A cross validation is performed to robustify the result \n",
    "    \n",
    "![img/cv.png](img/cv.png)  \n",
    "    \n",
    "Some tips and tricks and doc [here](https://scikit-learn.org/stable/modules/grid_search.html#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of test to launch\n",
    "NB_TRIAL = 3\n",
    "\n",
    "# List of parameters to tune and their ranges\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the tunning of hyper-parameters using the sklearn `RandomSearchCV` algorithm (google it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4/ Optimize hyper-parameters using `hyperopt`\n",
    "\n",
    "You can use a dedicated library to tune your hyper-parameters. Algorithm available are based on optimization techniques. \n",
    "\n",
    "This [post](https://towardsdatascience.com/hyperopt-demystified-3e14006eb6fa) details a lot what is behind it. In a nutshell, it is an iterative research algorithm based Expected Improvement computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this piece of code, find the better hyper parameters of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from: https://www.kaggle.com/code/merrickolivier/hyperopt-and-xgbregressor-bayesian-optimization/notebook\n",
    "\n",
    "NB_TRIAL = 3\n",
    "\n",
    "\n",
    "space = {'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),  # for a float value\n",
    "         'max_depth': hp.randint('max_depth', 2, 7)  # for an integer value\n",
    "        }\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    model = XGBRegressor(**space, verbosity=0)\n",
    "    \n",
    "    #Define evaluation datasets.\n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "    #Fit the model. Define evaluation sets, early_stopping_rounds, and eval_metric.\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              )\n",
    "\n",
    "    #Obtain prediction and rmse score.\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    print (\"SCORE:\", rmse)\n",
    "    \n",
    "    #Specify what the loss is for each model.\n",
    "    return {'loss':rmse, 'status': STATUS_OK, 'model': model}\n",
    "         \n",
    "         \n",
    "#Run 20 trials.\n",
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=NB_TRIAL,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate(XGBRegressor(**best), scaled=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
